{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5285da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "import time\n",
    "import csv\n",
    "import queue\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/beni/Desktop/Climbing Technique Tracker/Climbing_Tracker/pose_landmarker_full.task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The code in this block is partly taken from the official MediaPipe documentation and can be found \n",
    "here: https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker/python#live-stream_1\"\"\"\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "PoseLandmarkerResult = mp.tasks.vision.PoseLandmarkerResult\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "saved_results = queue.Queue()\n",
    "\n",
    "\n",
    "def print_result(result: PoseLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    print('pose landmarker result: {}'.format(result))\n",
    "    saved_results.put(result)\n",
    "    saved_results.put(timestamp_ms)\n",
    "\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM, #sets the running mode to live stream\n",
    "    result_callback=print_result)\n",
    "\n",
    "\n",
    "\"\"\"The following code is written by myself using the OpenCV and MediaPipe documentation for help which\n",
    "can be found in the readme file\"\"\"\n",
    "\n",
    "#check how many frames per second Qsense sensors output\n",
    "frames_per_second = 10\n",
    "time_between_frames = 1 / frames_per_second\n",
    "\n",
    "\n",
    "with PoseLandmarker.create_from_options(options) as landmarker:\n",
    "    #Use openCV VideoCapture to start capturing from the webcam\n",
    "    start_time = time.time()\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "\n",
    "    #Create a loop to read the latest frame from the camera using VideoCaptureRead()\n",
    "    while capture.isOpened():\n",
    "\n",
    "        ret, frame = capture.read()\n",
    "     \n",
    "        if not ret:\n",
    "            print(\"broken\")\n",
    "            break\n",
    "\n",
    "        #Convert the frame receieved from OpenCV to a MediaPipe Image Object\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "      \n",
    "        #landmarker.detect_async(mp_image, timestamp_ms = int(time.time() * 1000))\n",
    "        #from datetime import datetime\n",
    "        landmarker.detect_async(mp_image, int(datetime.now().timestamp() * 1000))\n",
    "\n",
    "\n",
    "        #color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('frame', frame) #first param is window name\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "        \"\"\"The following frame limiter was taken from the following online answer:\n",
    "         https://www.quora.com/How-do-I-decrease-the-frames-per-second-in-OpenCV-python\"\"\"\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        time_to_wait = time_between_frames - elapsed_time \n",
    "        if time_to_wait > 0: \n",
    "            time.sleep(time_to_wait)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_elbow_angle(shoulder_landmark, elbow_landmark, wrist_landmark):\n",
    "\n",
    "    #convert landmark coordinates into vectors\n",
    "    \n",
    "    vector_s_e = [shoulder_landmark.x - elbow_landmark.x, shoulder_landmark.y - elbow_landmark.y, shoulder_landmark.z - elbow_landmark.z]\n",
    "    vector_w_e = [wrist_landmark.x - elbow_landmark.x, wrist_landmark.y - elbow_landmark.y, wrist_landmark.z - elbow_landmark.z]\n",
    "\n",
    "    \"\"\"dot product of the two vectors: code adapted from \n",
    "    https://www.geeksforgeeks.org/python/how-to-calculate-dot-product-of-two-vectors-in-python/\"\"\" \n",
    "    dot_product = np.dot(vector_s_e, vector_w_e)\n",
    "\n",
    "    \"\"\"magnitude of the two vectors: code apated from\n",
    "    https://stackoverflow.com/questions/9171158/how-do-you-get-the-magnitude-of-a-vector-in-numpy\"\"\"\n",
    "    magnitude_vector_s_e = np.linalg.norm(vector_s_e)\n",
    "    magnitude_vector_w_e = np.linalg.norm(vector_w_e)\n",
    "\n",
    "    \"\"\"final equation to calculate angle\"\"\"\n",
    "    angle = math.degrees(math.acos(dot_product / ((magnitude_vector_s_e) * (magnitude_vector_w_e))))\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    ['time stamp', 'landmark #1', 'landmark #2', 'landmark #3', 'landmark #4', 'landmark #5',\n",
    "    'landmark #6', 'landmark #7', 'landmark #8', 'landmark #9', 'landmark #10', 'landmark #11',\n",
    "    'landmark #12', 'landmark #13', 'landmark #14', 'landmark #15', 'landmark #16', 'landmark #17',\n",
    "    'landmark #18', 'landmark #19', 'landmark #20', 'landmark #21', 'landmark #22', 'landmark #23',\n",
    "    'landmark #24', 'landmark #25', 'landmark #26', 'landmark #27', 'landmark #28', 'landmark #29',\n",
    "    'landmark #30','landmark #31','landmark #32', 'elbow angle']\n",
    "]\n",
    "while not saved_results.empty():\n",
    "    \n",
    "    landmark = saved_results.get() #get pose_landmark for each frame\n",
    "    try:\n",
    "        landmarks = [] #initialize an array for each indidual landmark in a frame (33 total)\n",
    "        for i in range(0,32):\n",
    "            landmark_point = landmark.pose_landmarks[0][i] #get each landmark (0, 32) for the 0th person in the frame\n",
    "            landmarks.append(landmark_point)\n",
    "    except:\n",
    "        print(\"no landmarks detected\") #first couple frames might not detect a person yet\n",
    "\n",
    "    #calculate elbow angle\n",
    "    try:\n",
    "        elbow_ang = calculate_elbow_angle(landmark.pose_landmarks[0][12], landmark.pose_landmarks[0][14], landmark.pose_landmarks[0][16])\n",
    "        print(elbow_ang)\n",
    "    except:\n",
    "        print('no elbow angle detected')\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    time_stamp = saved_results.get() #get timestamp (comes after each landmark in the queue)\n",
    "    utc_tz = datetime.utcfromtimestamp(time_stamp / 1000) #convert to readable date time format\n",
    "    utc_plus_8_tz = utc_time + timedelta(hours=8) #adjust time zone from UTC to UTC + 8\n",
    "    \n",
    "    try:\n",
    "        results.append([utc_plus_8_tz]+ landmarks + [elbow_ang]) #append landmarks + timestamp into results array\n",
    "    except:\n",
    "         results.append([utc_plus_8_tz]+ landmarks)\n",
    "\n",
    "\"\"\"CSV code adapted from the following website: https://www.geeksforgeeks.org/python/writing-csv-files-in-python/\"\"\"\n",
    "\n",
    "#each frame is writen into the CSV, each column are the coordinates for a single landmark\n",
    "with open('results.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
